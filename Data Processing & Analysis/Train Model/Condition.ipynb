{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-20T06:29:10.559752Z",
     "start_time": "2024-10-20T06:29:09.943106Z"
    }
   },
   "source": [
    "import pyspark\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType, StringType, TimestampType"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T06:29:10.593762Z",
     "start_time": "2024-10-20T06:29:10.578763Z"
    }
   },
   "cell_type": "code",
   "source": "from pyspark.sql import SparkSession",
   "id": "1001e7e09a0bf3d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T06:29:40.907920Z",
     "start_time": "2024-10-20T06:29:12.672767Z"
    }
   },
   "cell_type": "code",
   "source": "spark=SparkSession.builder.appName('Practise').getOrCreate()",
   "id": "a8c9117270c6924b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T06:29:45.343440Z",
     "start_time": "2024-10-20T06:29:40.935930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def define_schema():\n",
    "    return StructType([\n",
    "        StructField(\"equipment_id\", IntegerType(), True),\n",
    "        StructField(\"timestamp\", TimestampType(), True),\n",
    "        StructField(\"temperature\", DoubleType(), True),\n",
    "        StructField(\"vibration\", DoubleType(), True),\n",
    "        StructField(\"pressure\", DoubleType(), True),\n",
    "        StructField(\"rotational_speed\", DoubleType(), True),\n",
    "        StructField(\"power_output\", DoubleType(), True),\n",
    "        StructField(\"noise_level\", DoubleType(), True),\n",
    "        StructField(\"voltage\", DoubleType(), True),\n",
    "        StructField(\"current\", DoubleType(), True),\n",
    "        StructField(\"oil_viscosity\", DoubleType(), True),\n",
    "        StructField(\"model\", StringType(), True),\n",
    "        StructField(\"manufacturer\", StringType(), True),\n",
    "        StructField(\"installation_date\", TimestampType(), True),\n",
    "        StructField(\"max_temperature\", DoubleType(), True),\n",
    "        StructField(\"max_pressure\", DoubleType(), True),\n",
    "        StructField(\"max_rotational_speed\", DoubleType(), True),\n",
    "        StructField(\"expected_lifetime_years\", DoubleType(), True),\n",
    "        StructField(\"warranty_period_years\", IntegerType(), True),\n",
    "        StructField(\"last_major_overhaul\", TimestampType(), True),\n",
    "        StructField(\"location\", StringType(), True),\n",
    "        StructField(\"criticality\", StringType(), True),\n",
    "        StructField(\"maintenance_type\", StringType(), True),\n",
    "        StructField(\"description\", StringType(), True),\n",
    "        StructField(\"technician_id\", IntegerType(), True),\n",
    "        StructField(\"duration_hours\", DoubleType(), True),\n",
    "        StructField(\"cost\", DoubleType(), True),\n",
    "        StructField(\"parts_replaced\", StringType(), True),\n",
    "        StructField(\"maintenance_result\", StringType(), True),\n",
    "        StructField(\"maintenance_date\", TimestampType(), True),\n",
    "        StructField(\"production_rate\", DoubleType(), True),\n",
    "        StructField(\"operating_hours\", DoubleType(), True),\n",
    "        StructField(\"downtime_hours\", DoubleType(), True),\n",
    "        StructField(\"operator_id\", IntegerType(), True),\n",
    "        StructField(\"product_type\", StringType(), True),\n",
    "        StructField(\"raw_material_quality\", StringType(), True),\n",
    "        StructField(\"ambient_temperature\", DoubleType(), True),\n",
    "        StructField(\"ambient_humidity\", DoubleType(), True),\n",
    "        StructField(\"operation_date\", TimestampType(), True),\n",
    "        StructField(\"days_since_maintenance\", IntegerType(), True),\n",
    "        StructField(\"equipment_age_days\", IntegerType(), True),\n",
    "        StructField(\"days_since_overhaul\", IntegerType(), True),\n",
    "        StructField(\"temp_pct_of_max\", DoubleType(), True),\n",
    "        StructField(\"pressure_pct_of_max\", DoubleType(), True),\n",
    "        StructField(\"speed_pct_of_max\", DoubleType(), True),\n",
    "        StructField(\"cumulative_maintenance_cost\", DoubleType(), True),\n",
    "        StructField(\"cumulative_operating_hours\", DoubleType(), True),\n",
    "        StructField(\"estimated_rul\", DoubleType(), True),\n",
    "        StructField(\"criticality_encoded\", DoubleType(), True),\n",
    "        StructField(\"maintenance_type_encoded\", DoubleType(), True),\n",
    "        StructField(\"maintenance_result_encoded\", DoubleType(), True),\n",
    "        StructField(\"product_type_encoded\", DoubleType(), True),\n",
    "        StructField(\"raw_material_quality_encoded\", DoubleType(), True),\n",
    "        StructField(\"parts_replaced_encoded\", DoubleType(), True)\n",
    "    ])\n",
    "schema = define_schema()\n",
    "df_pyspark = spark.read.csv(\"C:\\\\Users\\\\admin\\\\Desktop\\\\University\\\\Big Data\\\\Predictive-Maintenance-System-using-Apache-Spark\\\\Data Processing & Analysis\\\\Dataset\\\\final_data_update.csv\",header=True, schema = schema)\n",
    "df_pyspark.printSchema()"
   ],
   "id": "ca20df2241ded58a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- equipment_id: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- temperature: double (nullable = true)\n",
      " |-- vibration: double (nullable = true)\n",
      " |-- pressure: double (nullable = true)\n",
      " |-- rotational_speed: double (nullable = true)\n",
      " |-- power_output: double (nullable = true)\n",
      " |-- noise_level: double (nullable = true)\n",
      " |-- voltage: double (nullable = true)\n",
      " |-- current: double (nullable = true)\n",
      " |-- oil_viscosity: double (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- manufacturer: string (nullable = true)\n",
      " |-- installation_date: timestamp (nullable = true)\n",
      " |-- max_temperature: double (nullable = true)\n",
      " |-- max_pressure: double (nullable = true)\n",
      " |-- max_rotational_speed: double (nullable = true)\n",
      " |-- expected_lifetime_years: double (nullable = true)\n",
      " |-- warranty_period_years: integer (nullable = true)\n",
      " |-- last_major_overhaul: timestamp (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- criticality: string (nullable = true)\n",
      " |-- maintenance_type: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- technician_id: integer (nullable = true)\n",
      " |-- duration_hours: double (nullable = true)\n",
      " |-- cost: double (nullable = true)\n",
      " |-- parts_replaced: string (nullable = true)\n",
      " |-- maintenance_result: string (nullable = true)\n",
      " |-- maintenance_date: timestamp (nullable = true)\n",
      " |-- production_rate: double (nullable = true)\n",
      " |-- operating_hours: double (nullable = true)\n",
      " |-- downtime_hours: double (nullable = true)\n",
      " |-- operator_id: integer (nullable = true)\n",
      " |-- product_type: string (nullable = true)\n",
      " |-- raw_material_quality: string (nullable = true)\n",
      " |-- ambient_temperature: double (nullable = true)\n",
      " |-- ambient_humidity: double (nullable = true)\n",
      " |-- operation_date: timestamp (nullable = true)\n",
      " |-- days_since_maintenance: integer (nullable = true)\n",
      " |-- equipment_age_days: integer (nullable = true)\n",
      " |-- days_since_overhaul: integer (nullable = true)\n",
      " |-- temp_pct_of_max: double (nullable = true)\n",
      " |-- pressure_pct_of_max: double (nullable = true)\n",
      " |-- speed_pct_of_max: double (nullable = true)\n",
      " |-- cumulative_maintenance_cost: double (nullable = true)\n",
      " |-- cumulative_operating_hours: double (nullable = true)\n",
      " |-- estimated_rul: double (nullable = true)\n",
      " |-- criticality_encoded: double (nullable = true)\n",
      " |-- maintenance_type_encoded: double (nullable = true)\n",
      " |-- maintenance_result_encoded: double (nullable = true)\n",
      " |-- product_type_encoded: double (nullable = true)\n",
      " |-- raw_material_quality_encoded: double (nullable = true)\n",
      " |-- parts_replaced_encoded: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T06:29:53.745733Z",
     "start_time": "2024-10-20T06:29:45.542452Z"
    }
   },
   "cell_type": "code",
   "source": "df_pyspark.show(10)",
   "id": "17232388c164b382",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-----------+----------+---------+----------------+------------+-----------+---------+----------+-------------+----------+-------------+--------------------+---------------+------------+--------------------+-----------------------+---------------------+--------------------+---------+-----------+----------------+--------------------+-------------+--------------+---------+--------------+------------------+--------------------+---------------+---------------+--------------+-----------+------------+--------------------+-------------------+----------------+--------------------+----------------------+------------------+-------------------+------------------+-------------------+-----------------+---------------------------+--------------------------+-------------+-------------------+------------------------+--------------------------+--------------------+----------------------------+----------------------+\n",
      "|equipment_id|           timestamp|temperature| vibration| pressure|rotational_speed|power_output|noise_level|  voltage|   current|oil_viscosity|     model| manufacturer|   installation_date|max_temperature|max_pressure|max_rotational_speed|expected_lifetime_years|warranty_period_years| last_major_overhaul| location|criticality|maintenance_type|         description|technician_id|duration_hours|     cost|parts_replaced|maintenance_result|    maintenance_date|production_rate|operating_hours|downtime_hours|operator_id|product_type|raw_material_quality|ambient_temperature|ambient_humidity|      operation_date|days_since_maintenance|equipment_age_days|days_since_overhaul|   temp_pct_of_max|pressure_pct_of_max| speed_pct_of_max|cumulative_maintenance_cost|cumulative_operating_hours|estimated_rul|criticality_encoded|maintenance_type_encoded|maintenance_result_encoded|product_type_encoded|raw_material_quality_encoded|parts_replaced_encoded|\n",
      "+------------+--------------------+-----------+----------+---------+----------------+------------+-----------+---------+----------+-------------+----------+-------------+--------------------+---------------+------------+--------------------+-----------------------+---------------------+--------------------+---------+-----------+----------------+--------------------+-------------+--------------+---------+--------------+------------------+--------------------+---------------+---------------+--------------+-----------+------------+--------------------+-------------------+----------------+--------------------+----------------------+------------------+-------------------+------------------+-------------------+-----------------+---------------------------+--------------------------+-------------+-------------------+------------------------+--------------------------+--------------------+----------------------------+----------------------+\n",
      "|           1|2021-10-10 13:33:...|  63.102325|  0.583735|111.57932|        978.9937|    579.5041|  72.580185| 217.1716| 116.37518|     42.70299|Model-1951|ManufacturerC|2020-05-25 13:34:...|       83.86452|   187.45992|           1243.6407|             11.8686285|                    3|2025-04-03 13:34:...|Section-4|     Medium|         Routine|Routine maintenan...|           22|      6.964117|1218.1901|          None|        Successful|2024-08-12 13:34:...|       94.49336|       20.01369|    0.58859503|         89|       TypeA|                High|          22.501215|       32.179783|2021-10-10 13:34:...|                  1037|               503|               1271|  75.2431719635431|  59.52169402398123|78.71997917083287|                  1218.1901|                  20.01369| 3829.0494025|                0.0|                     2.0|                       0.0|                 1.0|                         0.0|                   0.0|\n",
      "|           1|2021-10-10 19:33:...|  66.560684| 0.5780538| 58.56234|       1109.8779|    485.0838|  76.433655|236.80861|  94.50009|     54.63073|Model-1951|ManufacturerC|2020-05-25 13:34:...|       83.86452|   187.45992|           1243.6407|             11.8686285|                    3|2025-04-03 13:34:...|Section-4|     Medium|         Routine|Routine maintenan...|           22|      6.964117|1218.1901|          None|        Successful|2024-08-12 13:34:...|       94.49336|       20.01369|    0.58859503|         89|       TypeA|                High|          22.501215|       32.179783|2021-10-10 13:34:...|                  1037|               503|               1271| 79.36691702283635| 31.239925846548957|89.24425680182388|                  2436.3802|                  40.02738| 3829.0494025|                0.0|                     2.0|                       0.0|                 1.0|                         0.0|                   0.0|\n",
      "|           1|2021-10-11 01:33:...|   47.79757|0.48461118| 56.58919|       1046.2716|   547.77606|  61.318645|224.70499| 91.184074|     53.11147|Model-1951|ManufacturerC|2020-05-25 13:34:...|       83.86452|   187.45992|           1243.6407|             11.8686285|                    3|2025-04-03 13:34:...|Section-4|     Medium|         Routine|Routine maintenan...|           22|      6.964117|1218.1901|          None|        Successful|2024-08-12 13:34:...|       91.30134|      20.773722|     1.3544766|         57|       TypeC|                High|          28.017666|        32.21979|2021-10-11 13:34:...|                  1036|               504|               1270|56.993791891970524|  30.18735418216331|84.12973296869426|         3654.5703000000003|                 60.801102| 3828.0494025|                0.0|                     2.0|                       0.0|                 0.0|                         0.0|                   0.0|\n",
      "|           1|2021-10-11 07:33:...|  53.125355|0.46519247|114.01153|       746.84045|    576.1142|   74.14918|  214.704|111.522675|     52.68492|Model-1951|ManufacturerC|2020-05-25 13:34:...|       83.86452|   187.45992|           1243.6407|             11.8686285|                    3|2025-04-03 13:34:...|Section-4|     Medium|         Routine|Routine maintenan...|           22|      6.964117|1218.1901|          None|        Successful|2024-08-12 13:34:...|       91.30134|      20.773722|     1.3544766|         57|       TypeC|                High|          28.017666|        32.21979|2021-10-11 13:34:...|                  1036|               504|               1270| 63.34663931779494|  60.81915003484477|60.05275076635881|                  4872.7604|                 81.574824| 3828.0494025|                0.0|                     2.0|                       0.0|                 0.0|                         0.0|                   0.0|\n",
      "|           1|2021-10-11 13:33:...|  53.964127|0.49352926|  98.2447|       1109.0782|    524.4226|   67.25192|219.81172|112.519264|      50.9315|Model-1951|ManufacturerC|2020-05-25 13:34:...|       83.86452|   187.45992|           1243.6407|             11.8686285|                    3|2025-04-03 13:34:...|Section-4|     Medium|         Routine|Routine maintenan...|           22|      6.964117|1218.1901|          None|        Successful|2024-08-12 13:34:...|       91.30134|      20.773722|     1.3544766|         57|       TypeC|                High|          28.017666|        32.21979|2021-10-11 13:34:...|                  1036|               504|               1270| 64.34679051403383|  52.40837614781868|89.17995366346567|                  6090.9505|                102.348546| 3828.0494025|                0.0|                     2.0|                       0.0|                 0.0|                         0.0|                   0.0|\n",
      "|           1|2021-10-11 19:33:...|   70.08919|0.53343683| 127.6598|        857.4468|   552.23175|  69.872986|232.73808|  70.89996|    55.812145|Model-1951|ManufacturerC|2020-05-25 13:34:...|       83.86452|   187.45992|           1243.6407|             11.8686285|                    3|2025-04-03 13:34:...|Section-4|     Medium|         Routine|Routine maintenan...|           22|      6.964117|1218.1901|          None|        Successful|2024-08-12 13:34:...|       91.30134|      20.773722|     1.3544766|         57|       TypeC|                High|          28.017666|        32.21979|2021-10-11 13:34:...|                  1036|               504|               1270| 83.57430532005668|  68.09978367642535|68.94650520845772|                  7309.1406|        123.12226799999999| 3828.0494025|                0.0|                     2.0|                       0.0|                 0.0|                         0.0|                   0.0|\n",
      "|           1|2021-10-12 01:33:...|    74.9544| 0.5274393|102.39677|         969.122|   559.50836|   66.44574| 235.6383|   108.852|     54.44558|Model-1951|ManufacturerC|2020-05-25 13:34:...|       83.86452|   187.45992|           1243.6407|             11.8686285|                    3|2025-04-03 13:34:...|Section-4|     Medium|         Routine|Routine maintenan...|           22|      6.964117|1218.1901|          None|        Successful|2024-08-12 13:34:...|      89.607666|      20.424337|     0.3715631|         12|       TypeC|                High|          20.725971|       57.952446|2021-10-12 13:34:...|                  1035|               505|               1269| 89.37557861178959|  54.62328694048306|77.92620489181482|                  8527.3307|                143.546605| 3827.0494025|                0.0|                     2.0|                       0.0|                 0.0|                         0.0|                   0.0|\n",
      "|           1|2021-10-12 07:33:...|  59.535942|0.44953424|113.06311|       1087.7844|   486.14938|  60.069717| 223.2198| 101.14837|    47.730507|Model-1951|ManufacturerC|2020-05-25 13:34:...|       83.86452|   187.45992|           1243.6407|             11.8686285|                    3|2025-04-03 13:34:...|Section-4|     Medium|         Routine|Routine maintenan...|           22|      6.964117|1218.1901|          None|        Successful|2024-08-12 13:34:...|      89.607666|      20.424337|     0.3715631|         12|       TypeC|                High|          20.725971|       57.952446|2021-10-12 13:34:...|                  1035|               505|               1269| 70.99061915575263| 60.313217886788806|87.46773887345437|                  9745.5208|                163.970942| 3827.0494025|                0.0|                     2.0|                       0.0|                 0.0|                         0.0|                   0.0|\n",
      "|           1|2021-10-12 13:33:...|  56.412777|0.34479618|122.28977|       990.41327|   466.04745|   68.80365|211.35019|  94.41844|    46.694633|Model-1951|ManufacturerC|2020-05-25 13:34:...|       83.86452|   187.45992|           1243.6407|             11.8686285|                    3|2025-04-03 13:34:...|Section-4|     Medium|         Routine|Routine maintenan...|           22|      6.964117|1218.1901|          None|        Successful|2024-08-12 13:34:...|      89.607666|      20.424337|     0.3715631|         12|       TypeC|                High|          20.725971|       57.952446|2021-10-12 13:34:...|                  1035|               505|               1269|  67.2665592076363|  65.23515533347076|79.63821624686295|                 10963.7109|        184.39527900000002| 3827.0494025|                0.0|                     2.0|                       0.0|                 0.0|                         0.0|                   0.0|\n",
      "|           1|2021-10-12 19:33:...|  63.212658| 0.5264704|111.12285|       1112.3331|   530.98645|    70.8878|230.28967|  90.37491|     53.20653|Model-1951|ManufacturerC|2020-05-25 13:34:...|       83.86452|   187.45992|           1243.6407|             11.8686285|                    3|2025-04-03 13:34:...|Section-4|     Medium|         Routine|Routine maintenan...|           22|      6.964117|1218.1901|          None|        Successful|2024-08-12 13:34:...|      89.607666|      20.424337|     0.3715631|         12|       TypeC|                High|          20.725971|       57.952446|2021-10-12 13:34:...|                  1035|               505|               1269| 75.37473296216326| 59.278191306173596|89.44167716608182|                  12181.901|        204.81961600000002| 3827.0494025|                0.0|                     2.0|                       0.0|                 0.0|                         0.0|                   0.0|\n",
      "+------------+--------------------+-----------+----------+---------+----------------+------------+-----------+---------+----------+-------------+----------+-------------+--------------------+---------------+------------+--------------------+-----------------------+---------------------+--------------------+---------+-----------+----------------+--------------------+-------------+--------------+---------+--------------+------------------+--------------------+---------------+---------------+--------------+-----------+------------+--------------------+-------------------+----------------+--------------------+----------------------+------------------+-------------------+------------------+-------------------+-----------------+---------------------------+--------------------------+-------------+-------------------+------------------------+--------------------------+--------------------+----------------------------+----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Temperature #",
   "id": "e43f9514112f2ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:31:30.369078Z",
     "start_time": "2024-10-20T08:31:03.074997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate the 60th and 90th percentiles for the temperature column\n",
    "temperature_percentiles = df_pyspark.approxQuantile(\"temperature\", [0.6, 0.9], 0.0)\n",
    "\n",
    "# Extract the 60th and 90th percentile values\n",
    "temperature_60th = temperature_percentiles[0]\n",
    "temperature_90th = temperature_percentiles[1]\n",
    "\n",
    "# Print the thresholds\n",
    "print(f\"Temperature 60th percentile (Normal to Warning boundary): {temperature_60th}\")\n",
    "print(f\"Temperature 90th percentile (Warning to Danger boundary): {temperature_90th}\")"
   ],
   "id": "8839c5d0afc8d3be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature 60th percentile (Normal to Warning boundary): 62.538803\n",
      "Temperature 90th percentile (Warning to Danger boundary): 72.82962\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:31:30.765023Z",
     "start_time": "2024-10-20T08:31:30.480087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import when\n",
    "# Create a new column 'temperature_category' based on the 60th and 90th percentile thresholds\n",
    "df_pyspark = df_pyspark.withColumn(\n",
    "    \"temperature_category\",\n",
    "    when(df_pyspark[\"temperature\"] <= temperature_60th, \"Normal\")\n",
    "    .when((df_pyspark[\"temperature\"] > temperature_60th) & (df_pyspark[\"temperature\"] <= temperature_90th), \"Warning\")\n",
    "    .otherwise(\"Danger\")\n",
    ")\n",
    "\n",
    "# Show the result for temperature categories\n",
    "df_pyspark.select(\"temperature\", \"temperature_category\").show(10)"
   ],
   "id": "4368d3ebb6c26358",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|temperature|temperature_category|\n",
      "+-----------+--------------------+\n",
      "|  63.102325|             Warning|\n",
      "|  66.560684|             Warning|\n",
      "|   47.79757|              Normal|\n",
      "|  53.125355|              Normal|\n",
      "|  53.964127|              Normal|\n",
      "|   70.08919|             Warning|\n",
      "|    74.9544|              Danger|\n",
      "|  59.535942|              Normal|\n",
      "|  56.412777|              Normal|\n",
      "|  63.212658|             Warning|\n",
      "+-----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:31:45.021675Z",
     "start_time": "2024-10-20T08:31:30.840032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate total rows for temperature\n",
    "total_rows_temperature = df_pyspark.count()\n",
    "\n",
    "# Group by temperature_category and calculate counts\n",
    "category_distribution_temperature = df_pyspark.groupBy(\"temperature_category\").count()\n",
    "\n",
    "# Calculate percentages for temperature\n",
    "category_distribution_temperature = category_distribution_temperature.withColumn(\n",
    "    \"percentage\", (category_distribution_temperature[\"count\"] / total_rows_temperature) * 100\n",
    ")\n",
    "\n",
    "# Show the distribution for temperature categories\n",
    "category_distribution_temperature.show()"
   ],
   "id": "2486b75c73ba99e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+----------+\n",
      "|temperature_category|  count|percentage|\n",
      "+--------------------+-------+----------+\n",
      "|              Danger| 437800|      10.0|\n",
      "|             Warning|1313400|      30.0|\n",
      "|              Normal|2626800|      60.0|\n",
      "+--------------------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pressure #",
   "id": "e2d320cd82b05194"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T15:34:14.539722Z",
     "start_time": "2024-10-19T15:33:51.932163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Calculate the 60th and 90th percentiles for the pressure column\n",
    "# pressure_percentiles = df_pyspark.approxQuantile(\"pressure\", [0.6, 0.9], 0.0)\n",
    "# \n",
    "# # Extract the 60th and 90th percentile values\n",
    "# pressure_60th = pressure_percentiles[0]  # 60th percentile (Normal -> Warning boundary)\n",
    "# pressure_90th = pressure_percentiles[1]  # 90th percentile (Warning -> Danger boundary)\n",
    "# \n",
    "# # Print the thresholds\n",
    "# print(f\"Pressure 60th percentile (Normal to Warning boundary): {pressure_60th}\")\n",
    "# print(f\"Pressure 90th percentile (Warning to Danger boundary): {pressure_90th}\")"
   ],
   "id": "f2138023235e147a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pressure 60th percentile (Normal to Warning boundary): 105.05247\n",
      "Pressure 90th percentile (Warning to Danger boundary): 125.62983\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T15:34:15.435Z",
     "start_time": "2024-10-19T15:34:14.621762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from pyspark.sql.functions import when\n",
    "# \n",
    "# # Create a new column 'pressure_category' based on the 60th and 90th percentile thresholds\n",
    "# df_pyspark = df_pyspark.withColumn(\n",
    "#     \"pressure_category\",\n",
    "#     when(df_pyspark[\"pressure\"] <= pressure_60th, \"Normal\")\n",
    "#     .when((df_pyspark[\"pressure\"] > pressure_60th) & (df_pyspark[\"pressure\"] <= pressure_90th), \"Warning\")\n",
    "#     .otherwise(\"Danger\")\n",
    "# )\n",
    "# \n",
    "# # Show the result with the pressure categories\n",
    "# df_pyspark.select(\"pressure\", \"pressure_category\").show(10)"
   ],
   "id": "baf536d4c02e6ef0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+\n",
      "| pressure|pressure_category|\n",
      "+---------+-----------------+\n",
      "|111.57932|          Warning|\n",
      "| 58.56234|           Normal|\n",
      "| 56.58919|           Normal|\n",
      "|114.01153|          Warning|\n",
      "|  98.2447|           Normal|\n",
      "| 127.6598|           Danger|\n",
      "|102.39677|           Normal|\n",
      "|113.06311|          Warning|\n",
      "|122.28977|          Warning|\n",
      "|111.12285|          Warning|\n",
      "+---------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:31:45.509780Z",
     "start_time": "2024-10-20T08:31:45.231753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Define a function to classify the pressure based on custom thresholds\n",
    "def check_pressure(df, pressure_column=\"pressure\"):\n",
    "    df = df.withColumn(\n",
    "        \"pressure_category\",\n",
    "        when(df[pressure_column] <= 120, \"Normal\")\n",
    "        .when((df[pressure_column] > 120) & (df[pressure_column] <= 140), \"Warning\")\n",
    "        .otherwise(\"Danger\")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Apply the function to classify pressure based on the custom thresholds\n",
    "df_pyspark = check_pressure(df_pyspark)\n",
    "\n",
    "# Show the result\n",
    "df_pyspark.select(\"pressure\", \"pressure_category\").show(10)"
   ],
   "id": "51a3c0431d608edc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+\n",
      "| pressure|pressure_category|\n",
      "+---------+-----------------+\n",
      "|111.57932|           Normal|\n",
      "| 58.56234|           Normal|\n",
      "| 56.58919|           Normal|\n",
      "|114.01153|           Normal|\n",
      "|  98.2447|           Normal|\n",
      "| 127.6598|          Warning|\n",
      "|102.39677|           Normal|\n",
      "|113.06311|           Normal|\n",
      "|122.28977|          Warning|\n",
      "|111.12285|           Normal|\n",
      "+---------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:32:01.610627Z",
     "start_time": "2024-10-20T08:31:45.651794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate total rows\n",
    "total_rows = df_pyspark.count()\n",
    "\n",
    "# Group by pressure_category and calculate counts\n",
    "category_distribution = df_pyspark.groupBy(\"pressure_category\").count()\n",
    "\n",
    "# Calculate percentages\n",
    "category_distribution = category_distribution.withColumn(\n",
    "    \"percentage\", (category_distribution[\"count\"] / total_rows) * 100\n",
    ")\n",
    "\n",
    "# Show the distribution\n",
    "category_distribution.show()"
   ],
   "id": "d3142b6e45cc30a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+------------------+\n",
      "|pressure_category|  count|        percentage|\n",
      "+-----------------+-------+------------------+\n",
      "|           Danger|  99495| 2.272613065326633|\n",
      "|          Warning| 594786|13.585792599360438|\n",
      "|           Normal|3683719| 84.14159433531293|\n",
      "+-----------------+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T06:36:14.514593Z",
     "start_time": "2024-10-20T06:36:06.940362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Filter rows where the pressure category is 'Normal'\n",
    "normal_pressure_rows = df_pyspark.filter(df_pyspark[\"pressure_category\"] == \"Normal\")\n",
    "\n",
    "# Find the maximum pressure value in the 'Normal' category\n",
    "max_normal_pressure = normal_pressure_rows.agg({\"pressure\": \"max\"}).collect()[0][0]\n",
    "\n",
    "# Print the result\n",
    "print(f\"The maximum pressure value for 'Normal' category is: {max_normal_pressure}\")"
   ],
   "id": "9f76d689b3d42e81",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum pressure value for 'Normal' category is: 179.45386\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Rotational speed #",
   "id": "f5ac885d2409d5ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T15:34:49.295014Z",
     "start_time": "2024-10-19T15:34:27.137298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Calculate the 60th and 90th percentiles for the rotational_speed column\n",
    "# rotational_speed_percentiles = df_pyspark.approxQuantile(\"rotational_speed\", [0.6, 0.9], 0.0)\n",
    "# \n",
    "# # Extract the 60th and 90th percentile values\n",
    "# rotational_speed_60th = rotational_speed_percentiles[0]\n",
    "# # rotational_speed_90th = rotational_speed_percentiles[1]\n",
    "# \n",
    "# # Print the thresholds\n",
    "# print(f\"Rotational Speed 60th percentile (Normal to Warning boundary): {rotational_speed_60th}\")\n",
    "# print(f\"Rotational Speed 90th percentile (Warning to Danger boundary): {rotational_speed_90th}\")"
   ],
   "id": "8fd59c0e4fe5c103",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotational Speed 60th percentile (Normal to Warning boundary): 1025.2911\n",
      "Rotational Speed 90th percentile (Warning to Danger boundary): 1128.142\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T15:34:49.913959Z",
     "start_time": "2024-10-19T15:34:49.417210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Create a new column 'rotational_speed_category' based on the 60th and 90th percentile thresholds\n",
    "# df_pyspark = df_pyspark.withColumn(\n",
    "#     \"rotational_speed_category\",\n",
    "#     when(df_pyspark[\"rotational_speed\"] <= rotational_speed_60th, \"Normal\")\n",
    "#     .when((df_pyspark[\"rotational_speed\"] > rotational_speed_60th) & (df_pyspark[\"rotational_speed\"] <= rotational_speed_90th), \"Warning\")\n",
    "#     .otherwise(\"Danger\")\n",
    "# )\n",
    "# \n",
    "# # Show the result for rotational speed categories\n",
    "# df_pyspark.select(\"rotational_speed\", \"rotational_speed_category\").show(10)"
   ],
   "id": "cf3d22ded264fddf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------------+\n",
      "|rotational_speed|rotational_speed_category|\n",
      "+----------------+-------------------------+\n",
      "|        978.9937|                   Normal|\n",
      "|       1109.8779|                  Warning|\n",
      "|       1046.2716|                  Warning|\n",
      "|       746.84045|                   Normal|\n",
      "|       1109.0782|                  Warning|\n",
      "|        857.4468|                   Normal|\n",
      "|         969.122|                   Normal|\n",
      "|       1087.7844|                  Warning|\n",
      "|       990.41327|                   Normal|\n",
      "|       1112.3331|                  Warning|\n",
      "+----------------+-------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:32:02.406699Z",
     "start_time": "2024-10-20T08:32:01.740140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Define a function to classify the rotational_speed based on custom thresholds\n",
    "def check_rotational_speed(df, rotational_speed_column=\"rotational_speed\"):\n",
    "    df = df.withColumn(\n",
    "        \"rotational_speed_category\",\n",
    "        when(df[rotational_speed_column] <= 1100, \"Normal\")\n",
    "        .when((df[rotational_speed_column] > 1100) & (df[rotational_speed_column] <= 1200), \"Warning\")\n",
    "        .otherwise(\"Danger\")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Apply the function to classify rotational_speed based on the custom thresholds\n",
    "df_pyspark = check_rotational_speed(df_pyspark)\n",
    "\n",
    "# Show the result\n",
    "df_pyspark.select(\"rotational_speed\", \"rotational_speed_category\").show(10)"
   ],
   "id": "ed95ea987218b1a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------------+\n",
      "|rotational_speed|rotational_speed_category|\n",
      "+----------------+-------------------------+\n",
      "|        978.9937|                   Normal|\n",
      "|       1109.8779|                  Warning|\n",
      "|       1046.2716|                   Normal|\n",
      "|       746.84045|                   Normal|\n",
      "|       1109.0782|                  Warning|\n",
      "|        857.4468|                   Normal|\n",
      "|         969.122|                   Normal|\n",
      "|       1087.7844|                   Normal|\n",
      "|       990.41327|                   Normal|\n",
      "|       1112.3331|                  Warning|\n",
      "+----------------+-------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:32:14.254237Z",
     "start_time": "2024-10-20T08:32:02.464491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate total rows for rotational speed\n",
    "total_rows_rotational_speed = df_pyspark.count()\n",
    "\n",
    "# Group by rotational_speed_category and calculate counts\n",
    "category_distribution_rotational_speed = df_pyspark.groupBy(\"rotational_speed_category\").count()\n",
    "\n",
    "# Calculate percentages for rotational speed\n",
    "category_distribution_rotational_speed = category_distribution_rotational_speed.withColumn(\n",
    "    \"percentage\", (category_distribution_rotational_speed[\"count\"] / total_rows_rotational_speed) * 100\n",
    ")\n",
    "\n",
    "# Show the distribution for rotational speed categories\n",
    "category_distribution_rotational_speed.show()"
   ],
   "id": "638176fb1319358",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-------+-----------------+\n",
      "|rotational_speed_category|  count|       percentage|\n",
      "+-------------------------+-------+-----------------+\n",
      "|                   Danger|  99121|2.264070351758794|\n",
      "|                  Warning| 594963|13.58983554134308|\n",
      "|                   Normal|3683916|84.14609410689813|\n",
      "+-------------------------+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Noise level #",
   "id": "9fa8a1bd3e33afc9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T06:50:52.197408Z",
     "start_time": "2024-10-20T06:50:27.496339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Calculate the 60th and 90th percentiles for the noise_level column\n",
    "# noise_level_percentiles = df_pyspark.approxQuantile(\"noise_level\", [0.6, 0.9], 0.0)\n",
    "# \n",
    "# # Extract the 60th and 90th percentile values\n",
    "# noise_level_60th = noise_level_percentiles[0]\n",
    "# noise_level_90th = noise_level_percentiles[1]\n",
    "# \n",
    "# # Print the thresholds\n",
    "# print(f\"Noise Level 60th percentile (Normal to Warning boundary): {noise_level_60th}\")\n",
    "# print(f\"Noise Level 90th percentile (Warning to Danger boundary): {noise_level_90th}\")"
   ],
   "id": "d0aabcbcfb5de358",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Level 60th percentile (Normal to Warning boundary): 71.27011\n",
      "Noise Level 90th percentile (Warning to Danger boundary): 76.408516\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T06:50:52.572259Z",
     "start_time": "2024-10-20T06:50:52.315803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Create a new column 'noise_level_category' based on the 60th and 90th percentile thresholds\n",
    "# df_pyspark = df_pyspark.withColumn(\n",
    "#     \"noise_level_category\",\n",
    "#     when(df_pyspark[\"noise_level\"] <= noise_level_60th, \"Normal\")\n",
    "#     .when((df_pyspark[\"noise_level\"] > noise_level_60th) & (df_pyspark[\"noise_level\"] <= noise_level_90th), \"Warning\")\n",
    "#     .otherwise(\"Danger\")\n",
    "# )\n",
    "# \n",
    "# # Show the result for noise level categories\n",
    "# df_pyspark.select(\"noise_level\", \"noise_level_category\").show(10)"
   ],
   "id": "28792fa92a0dcac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|noise_level|noise_level_category|\n",
      "+-----------+--------------------+\n",
      "|  72.580185|             Warning|\n",
      "|  76.433655|              Danger|\n",
      "|  61.318645|              Normal|\n",
      "|   74.14918|             Warning|\n",
      "|   67.25192|              Normal|\n",
      "|  69.872986|              Normal|\n",
      "|   66.44574|              Normal|\n",
      "|  60.069717|              Normal|\n",
      "|   68.80365|              Normal|\n",
      "|    70.8878|              Normal|\n",
      "+-----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:26:02.446335Z",
     "start_time": "2024-10-20T08:26:01.387125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Define a function to classify the noise_level based on custom thresholds\n",
    "def check_noise_level(df, noise_level_column=\"noise_level\"):\n",
    "    df = df.withColumn(\n",
    "        \"noise_level_category\",\n",
    "        when(df[noise_level_column] <= 75, \"Normal\")\n",
    "        .when((df[noise_level_column] > 75) & (df[noise_level_column] <= 82), \"Warning\")\n",
    "        .otherwise(\"Danger\")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Apply the function to classify noise_level based on the custom thresholds\n",
    "df_pyspark = check_noise_level(df_pyspark)\n",
    "\n",
    "# Show the result\n",
    "df_pyspark.select(\"noise_level\", \"noise_level_category\").show(10)\n"
   ],
   "id": "ed4af23b62a85f5d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|noise_level|noise_level_category|\n",
      "+-----------+--------------------+\n",
      "|  72.580185|              Normal|\n",
      "|  76.433655|             Warning|\n",
      "|  61.318645|              Normal|\n",
      "|   74.14918|              Normal|\n",
      "|   67.25192|              Normal|\n",
      "|  69.872986|              Normal|\n",
      "|   66.44574|              Normal|\n",
      "|  60.069717|              Normal|\n",
      "|   68.80365|              Normal|\n",
      "|    70.8878|              Normal|\n",
      "+-----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:26:19.239297Z",
     "start_time": "2024-10-20T08:26:04.828117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate total rows for noise level\n",
    "total_rows_noise_level = df_pyspark.count()\n",
    "\n",
    "# Group by noise_level_category and calculate counts\n",
    "category_distribution_noise_level = df_pyspark.groupBy(\"noise_level_category\").count()\n",
    "\n",
    "# Calculate percentages for noise level\n",
    "category_distribution_noise_level = category_distribution_noise_level.withColumn(\n",
    "    \"percentage\", (category_distribution_noise_level[\"count\"] / total_rows_noise_level) * 100\n",
    ")\n",
    "\n",
    "# Show the distribution for noise level categories\n",
    "category_distribution_noise_level.show()"
   ],
   "id": "e1163e86451f5fb8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+------------------+\n",
      "|noise_level_category|  count|        percentage|\n",
      "+--------------------+-------+------------------+\n",
      "|              Danger|  36126|0.8251713111009593|\n",
      "|             Warning| 659198|15.057058017359527|\n",
      "|              Normal|3682676| 84.11777067153952|\n",
      "+--------------------+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Voltage #",
   "id": "8cb75559fffc52ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T06:51:25.620511Z",
     "start_time": "2024-10-20T06:51:03.720263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Calculate the 60th and 90th percentiles for the voltage column\n",
    "# voltage_percentiles = df_pyspark.approxQuantile(\"voltage\", [0.6, 0.9], 0.0)\n",
    "# \n",
    "# # Extract the 60th and 90th percentile values\n",
    "# voltage_60th = voltage_percentiles[0]\n",
    "# voltage_90th = voltage_percentiles[1]\n",
    "# \n",
    "# # Print the thresholds\n",
    "# print(f\"Voltage 60th percentile (Normal to Warning boundary): {voltage_60th}\")\n",
    "# print(f\"Voltage 90th percentile (Warning to Danger boundary): {voltage_90th}\")"
   ],
   "id": "30a20c12d76c6494",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voltage 60th percentile (Normal to Warning boundary): 222.5247\n",
      "Voltage 90th percentile (Warning to Danger boundary): 232.82051\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T06:51:26.040790Z",
     "start_time": "2024-10-20T06:51:25.738793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Create a new column 'voltage_category' based on the 60th and 90th percentile thresholds\n",
    "# df_pyspark = df_pyspark.withColumn(\n",
    "#     \"voltage_category\",\n",
    "#     when(df_pyspark[\"voltage\"] <= voltage_60th, \"Normal\")\n",
    "#     .when((df_pyspark[\"voltage\"] > voltage_60th) & (df_pyspark[\"voltage\"] <= voltage_90th), \"Warning\")\n",
    "#     .otherwise(\"Danger\")\n",
    "# )\n",
    "# \n",
    "# # Show the result for voltage categories\n",
    "# df_pyspark.select(\"voltage\", \"voltage_category\").show(10)"
   ],
   "id": "746be25d95bebd1b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+\n",
      "|  voltage|voltage_category|\n",
      "+---------+----------------+\n",
      "| 217.1716|          Normal|\n",
      "|236.80861|          Danger|\n",
      "|224.70499|         Warning|\n",
      "|  214.704|          Normal|\n",
      "|219.81172|          Normal|\n",
      "|232.73808|         Warning|\n",
      "| 235.6383|          Danger|\n",
      "| 223.2198|         Warning|\n",
      "|211.35019|          Normal|\n",
      "|230.28967|         Warning|\n",
      "+---------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:30:02.156526Z",
     "start_time": "2024-10-20T08:30:02.003521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Define a function to classify the voltage based on custom thresholds\n",
    "def check_voltage(df, voltage_column=\"voltage\"):\n",
    "    df = df.withColumn(\n",
    "        \"voltage_category\",\n",
    "        when(df[voltage_column] <= 225, \"Normal\")\n",
    "        .when((df[voltage_column] > 225) & (df[voltage_column] <= 237), \"Warning\")\n",
    "        .otherwise(\"Danger\")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Apply the function to classify voltage based on the custom thresholds\n",
    "df_pyspark = check_voltage(df_pyspark)\n",
    "\n",
    "# Show the result\n",
    "df_pyspark.select(\"voltage\", \"voltage_category\").show(10)"
   ],
   "id": "239be8c0870e210e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+\n",
      "|  voltage|voltage_category|\n",
      "+---------+----------------+\n",
      "| 217.1716|          Normal|\n",
      "|236.80861|         Warning|\n",
      "|224.70499|          Normal|\n",
      "|  214.704|          Normal|\n",
      "|219.81172|          Normal|\n",
      "|232.73808|         Warning|\n",
      "| 235.6383|         Warning|\n",
      "| 223.2198|          Normal|\n",
      "|211.35019|          Normal|\n",
      "|230.28967|         Warning|\n",
      "+---------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:30:15.134451Z",
     "start_time": "2024-10-20T08:30:04.974455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate total rows for voltage\n",
    "total_rows_voltage = df_pyspark.count()\n",
    "\n",
    "# Group by voltage_category and calculate counts\n",
    "category_distribution_voltage = df_pyspark.groupBy(\"voltage_category\").count()\n",
    "\n",
    "# Calculate percentages for voltage\n",
    "category_distribution_voltage = category_distribution_voltage.withColumn(\n",
    "    \"percentage\", (category_distribution_voltage[\"count\"] / total_rows_voltage) * 100\n",
    ")\n",
    "\n",
    "# Show the distribution for voltage categories\n",
    "category_distribution_voltage.show()"
   ],
   "id": "adb1a19a4497dfbd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+------------------+\n",
      "|voltage_category|  count|        percentage|\n",
      "+----------------+-------+------------------+\n",
      "|          Danger| 195225|4.4592279579716765|\n",
      "|         Warning|1154668|26.374326176336226|\n",
      "|          Normal|3028107|  69.1664458656921|\n",
      "+----------------+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:32:25.231567Z",
     "start_time": "2024-10-20T08:32:25.033300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Combine all the conditions into a single \"system_warning\" column, including the temperature_category\n",
    "df_pyspark = df_pyspark.withColumn(\n",
    "    \"system_warning\",\n",
    "    when(\n",
    "        (df_pyspark[\"pressure_category\"] == \"Danger\") |\n",
    "        (df_pyspark[\"rotational_speed_category\"] == \"Danger\") |\n",
    "        (df_pyspark[\"noise_level_category\"] == \"Danger\") |\n",
    "        (df_pyspark[\"voltage_category\"] == \"Danger\") |\n",
    "        (df_pyspark[\"temperature_category\"] == \"Danger\"), \"Danger\"\n",
    "    ).when(\n",
    "        (df_pyspark[\"pressure_category\"] == \"Warning\") |\n",
    "        (df_pyspark[\"rotational_speed_category\"] == \"Warning\") |\n",
    "        (df_pyspark[\"noise_level_category\"] == \"Warning\") |\n",
    "        (df_pyspark[\"voltage_category\"] == \"Warning\") |\n",
    "        (df_pyspark[\"temperature_category\"] == \"Warning\"), \"Warning\"\n",
    "    ).otherwise(\"Normal\")\n",
    ")\n",
    "\n",
    "# Drop the individual category columns if not needed\n",
    "df_pyspark = df_pyspark.drop(\"pressure_category\", \"rotational_speed_category\", \"noise_level_category\", \"voltage_category\", \"temperature_category\")\n",
    "\n",
    "# Show the result with just the system warning\n",
    "df_pyspark.select(\"system_warning\").show(10)"
   ],
   "id": "c19878c361979eeb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|system_warning|\n",
      "+--------------+\n",
      "|       Warning|\n",
      "|       Warning|\n",
      "|        Normal|\n",
      "|        Normal|\n",
      "|       Warning|\n",
      "|       Warning|\n",
      "|        Danger|\n",
      "|        Normal|\n",
      "|       Warning|\n",
      "|       Warning|\n",
      "+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:32:28.679726Z",
     "start_time": "2024-10-20T08:32:28.494907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_row_with_columns(df_pyspark, row_index):\n",
    "    # Use take to retrieve a specific row based on index\n",
    "    row = df_pyspark.take(row_index + 1)[-1]  # Retrieve only the row we are interested in\n",
    "\n",
    "    # Print the relevant columns and the system warning\n",
    "    print(f\"Temperature: {row['temperature']}\")\n",
    "    print(f\"Rotational Speed: {row['rotational_speed']}\")\n",
    "    print(f\"Noise Level: {row['noise_level']}\")\n",
    "    print(f\"Voltage: {row['voltage']}\")\n",
    "    print(f\"System Warning: {row['system_warning']}\")\n",
    "\n",
    "# Test the function by checking a specific row\n",
    "check_row_with_columns(df_pyspark, 0)  # Check the row at index 0"
   ],
   "id": "adfd9ea839a85813",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature: 63.102325\n",
      "Rotational Speed: 978.9937\n",
      "Noise Level: 72.580185\n",
      "Voltage: 217.1716\n",
      "System Warning: Warning\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:32:34.337689Z",
     "start_time": "2024-10-20T08:32:34.173350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_multiple_rows(df_pyspark, num_rows):\n",
    "    # Select the relevant columns\n",
    "    df_pyspark.select(\"pressure\",\"temperature\", \"rotational_speed\", \"noise_level\", \"voltage\", \"system_warning\").show(num_rows)\n",
    "\n",
    "# Show the first 5 rows as an example\n",
    "check_multiple_rows(df_pyspark, 5)\n"
   ],
   "id": "468e494983c8c145",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----------------+-----------+---------+--------------+\n",
      "| pressure|temperature|rotational_speed|noise_level|  voltage|system_warning|\n",
      "+---------+-----------+----------------+-----------+---------+--------------+\n",
      "|111.57932|  63.102325|        978.9937|  72.580185| 217.1716|       Warning|\n",
      "| 58.56234|  66.560684|       1109.8779|  76.433655|236.80861|       Warning|\n",
      "| 56.58919|   47.79757|       1046.2716|  61.318645|224.70499|        Normal|\n",
      "|114.01153|  53.125355|       746.84045|   74.14918|  214.704|        Normal|\n",
      "|  98.2447|  53.964127|       1109.0782|   67.25192|219.81172|       Warning|\n",
      "+---------+-----------+----------------+-----------+---------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train model #",
   "id": "f7fe80e697f0dfb7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:38:22.414883Z",
     "start_time": "2024-10-20T08:32:37.813355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Step 1: Split the dataset into training and test sets (80% train, 20% test)\n",
    "train_data, test_data = df_pyspark.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Step 2: Convert the 'system_warning' label to numeric using StringIndexer\n",
    "indexer = StringIndexer(inputCol=\"system_warning\", outputCol=\"label\")\n",
    "train_data = indexer.fit(train_data).transform(train_data)\n",
    "test_data = indexer.fit(test_data).transform(test_data)\n",
    "\n",
    "# Step 3: Assemble features (you can choose any relevant features for your model)\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        \"temperature\", \"rotational_speed\", \"noise_level\", \"voltage\", \n",
    "        \"pressure\"  # Add other features if needed\n",
    "    ],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "train_data = assembler.transform(train_data)\n",
    "test_data = assembler.transform(test_data)\n",
    "\n",
    "# Step 4: Train the model (RandomForestClassifier in this case)\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
    "model = rf.fit(train_data)\n",
    "\n",
    "# Step 5: Test the model on the test set\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Step 6: Evaluate the model using accuracy metric\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Test Accuracy = {accuracy}\")\n",
    "\n",
    "# Step 7: Show some of the predictions\n",
    "predictions.select(\"features\", \"system_warning\", \"prediction\").show(10)"
   ],
   "id": "c0107553243b5f03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.9328097202813982\n",
      "+--------------------+--------------+----------+\n",
      "|            features|system_warning|prediction|\n",
      "+--------------------+--------------+----------+\n",
      "|[47.79757,1046.27...|        Normal|       1.0|\n",
      "|[74.9544,969.122,...|        Danger|       2.0|\n",
      "|[56.412777,990.41...|       Warning|       0.0|\n",
      "|[66.40015,1223.64...|        Danger|       0.0|\n",
      "|[57.865803,1150.8...|       Warning|       0.0|\n",
      "|[71.06786,894.022...|       Warning|       0.0|\n",
      "|[46.005398,1091.1...|        Normal|       1.0|\n",
      "|[64.55505,1081.51...|       Warning|       0.0|\n",
      "|[44.598717,1020.5...|       Warning|       0.0|\n",
      "|[58.668625,1113.4...|       Warning|       0.0|\n",
      "+--------------------+--------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:39:47.034717Z",
     "start_time": "2024-10-20T08:38:33.892133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Filter out rows where prediction is incorrect\n",
    "misclassified = predictions.filter(predictions[\"system_warning\"] != predictions[\"prediction\"])\n",
    "misclassified.show(10)"
   ],
   "id": "54b323f41848d739",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+-----------+---------+--------+----------------+------------+-----------+-------+-------+-------------+-----+------------+-----------------+---------------+------------+--------------------+-----------------------+---------------------+-------------------+--------+-----------+----------------+-----------+-------------+--------------+----+--------------+------------------+----------------+---------------+---------------+--------------+-----------+------------+--------------------+-------------------+----------------+--------------+----------------------+------------------+-------------------+---------------+-------------------+----------------+---------------------------+--------------------------+-------------+-------------------+------------------------+--------------------------+--------------------+----------------------------+----------------------+--------------+--------------------+----------------+--------------------+-----------------+-------------------------+-----+--------+-------------+-----------+----------+\n",
      "|equipment_id|timestamp|temperature|vibration|pressure|rotational_speed|power_output|noise_level|voltage|current|oil_viscosity|model|manufacturer|installation_date|max_temperature|max_pressure|max_rotational_speed|expected_lifetime_years|warranty_period_years|last_major_overhaul|location|criticality|maintenance_type|description|technician_id|duration_hours|cost|parts_replaced|maintenance_result|maintenance_date|production_rate|operating_hours|downtime_hours|operator_id|product_type|raw_material_quality|ambient_temperature|ambient_humidity|operation_date|days_since_maintenance|equipment_age_days|days_since_overhaul|temp_pct_of_max|pressure_pct_of_max|speed_pct_of_max|cumulative_maintenance_cost|cumulative_operating_hours|estimated_rul|criticality_encoded|maintenance_type_encoded|maintenance_result_encoded|product_type_encoded|raw_material_quality_encoded|parts_replaced_encoded|system_warning|noise_level_category|voltage_category|temperature_category|pressure_category|rotational_speed_category|label|features|rawPrediction|probability|prediction|\n",
      "+------------+---------+-----------+---------+--------+----------------+------------+-----------+-------+-------+-------------+-----+------------+-----------------+---------------+------------+--------------------+-----------------------+---------------------+-------------------+--------+-----------+----------------+-----------+-------------+--------------+----+--------------+------------------+----------------+---------------+---------------+--------------+-----------+------------+--------------------+-------------------+----------------+--------------+----------------------+------------------+-------------------+---------------+-------------------+----------------+---------------------------+--------------------------+-------------+-------------------+------------------------+--------------------------+--------------------+----------------------------+----------------------+--------------+--------------------+----------------+--------------------+-----------------+-------------------------+-----+--------+-------------+-----------+----------+\n",
      "+------------+---------+-----------+---------+--------+----------------+------------+-----------+-------+-------+-------------+-----+------------+-----------------+---------------+------------+--------------------+-----------------------+---------------------+-------------------+--------+-----------+----------------+-----------+-------------+--------------+----+--------------+------------------+----------------+---------------+---------------+--------------+-----------+------------+--------------------+-------------------+----------------+--------------+----------------------+------------------+-------------------+---------------+-------------------+----------------+---------------------------+--------------------------+-------------+-------------------+------------------------+--------------------------+--------------------+----------------------------+----------------------+--------------+--------------------+----------------+--------------------+-----------------+-------------------------+-----+--------+-------------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T07:01:41.632252Z",
     "start_time": "2024-10-20T07:00:54.977591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check distinct values of system_warning and their corresponding labels\n",
    "predictions.select(\"system_warning\", \"label\").distinct().show()"
   ],
   "id": "6a4522dc2367d920",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|system_warning|label|\n",
      "+--------------+-----+\n",
      "|        Danger|  1.0|\n",
      "|       Warning|  0.0|\n",
      "|        Normal|  2.0|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T08:40:24.039942Z",
     "start_time": "2024-10-20T08:40:10.796642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Filter rows where the prediction is \"Normal\" (assuming 2.0 corresponds to \"Normal\")\n",
    "normal_predictions = predictions.filter(predictions[\"prediction\"] == 1.0)\n",
    "\n",
    "# Show the result\n",
    "normal_predictions.select(\"features\", \"system_warning\", \"prediction\").show(10)\n"
   ],
   "id": "391a46d1d1388286",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+----------+\n",
      "|            features|system_warning|prediction|\n",
      "+--------------------+--------------+----------+\n",
      "|[47.79757,1046.27...|        Normal|       1.0|\n",
      "|[46.005398,1091.1...|        Normal|       1.0|\n",
      "|[48.049965,1067.7...|        Normal|       1.0|\n",
      "|[43.988087,899.60...|        Normal|       1.0|\n",
      "|[56.312733,920.68...|        Normal|       1.0|\n",
      "|[41.80106,932.265...|        Normal|       1.0|\n",
      "|[61.451977,911.91...|        Normal|       1.0|\n",
      "|[53.29162,907.601...|        Normal|       1.0|\n",
      "|[38.411343,953.38...|        Normal|       1.0|\n",
      "|[53.78314,1090.20...|        Normal|       1.0|\n",
      "+--------------------+--------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T09:01:42.745045Z",
     "start_time": "2024-10-20T08:58:12.991368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate the total number of rows in the dataset\n",
    "total_rows = train_data.count()\n",
    "\n",
    "# Group by 'system_warning' and calculate the counts\n",
    "category_distribution = train_data.groupBy(\"system_warning\").count()\n",
    "\n",
    "# Calculate the percentages for each category\n",
    "category_distribution = category_distribution.withColumn(\n",
    "    \"percentage\", (category_distribution[\"count\"] / total_rows) * 100\n",
    ")\n",
    "\n",
    "# Show the result with both count and percentage\n",
    "category_distribution.show()"
   ],
   "id": "4437090c0233b113",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+------------------+\n",
      "|system_warning|  count|        percentage|\n",
      "+--------------+-------+------------------+\n",
      "|        Danger| 649439|18.540572839035296|\n",
      "|       Warning|1987822| 56.74953087516583|\n",
      "|        Normal| 865538| 24.70989628579887|\n",
      "+--------------+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Installation Date and Current Date #",
   "id": "59409e73ad281dcd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T15:41:34.444945Z",
     "start_time": "2024-10-19T15:41:34.441690Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1f8ea62da16ef370",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
